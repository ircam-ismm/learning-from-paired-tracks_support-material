<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Audio Demo: MoisesDB</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f4;
      padding: 20px;
    }
    .category-title {
      font-size: 1.5em;
      margin: 20px 0 10px;
      color: #333;
      text-align: center;
    }
    .memory-guide-row, .grid {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 10px;
      margin: 10px 0;
    }
    .audio-container {
      background: white;
      padding: 10px;
      border-radius: 8px;
      box-shadow: 0 0 8px rgba(0, 0, 0, 0.08);
      text-align: center;
      width: 30%;
      min-width: 200px;
    }
    .comment-box {
      display: block;
      width: 90%;
      margin: 20px auto;
    }
    .audio-container.large-audio {
      min-width: 300px;
      min-height: 120px;
      padding: 10px;
      box-sizing: border-box;
    }

    .comment-box {
      width: 100%;
      min-height: 60px;
      margin-top: 10px;
      padding: 8px;
      resize: vertical;
      font-size: 0.9rem;
    }

    textarea {
      width: 100%;
      padding: 10px;
      border-radius: 6px;
      border: 1px solid #ccc;
      resize: vertical;
    }
    hr.separator {
      border: none;
      border-top: 2px dashed #ccc;
      margin: 40px auto;
      width: 80%;
    }
    .summary-section {
      background: #ffffff;
      padding: 15px 20px;
      margin: 20px auto;
      border-left: 4px solid #007BFF;
      box-shadow: 0 0 8px rgba(0,0,0,0.08);
      border-radius: 8px;
      max-width: 1200px;
      line-height: 1.5;
    }
    .summary-section h3 {
      text-align: center;
      margin-bottom: 10px;
      color: #333;
    }
    .summary-section p {
      margin-bottom: 10px;
      text-align: justify;
    }
    .figures-section {
      background: #fff;
      padding: 15px 20px;
      margin: 20px auto;
      border-left: 4px solid #28a745;
      box-shadow: 0 0 8px rgba(0,0,0,0.08);
      border-radius: 8px;
      max-width: 900px;
    }
    .figures-section h3 {
      text-align: center;
      margin-bottom: 15px;
      color: #333;
    }
    .figure {
      margin-bottom: 25px;
      text-align: center;
    }
    .figure img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      box-shadow: 0 0 5px rgba(0,0,0,0.1);
    }
    .caption {
      font-size: 0.9em;
      color: #555;
      margin-top: 5px;
      font-style: italic;
    }
    .matrix-grid {
      display: grid;
      grid-template-columns: 100px repeat(3, 1fr);
      grid-template-rows: auto repeat(3, auto);
      gap: 10px;
      align-items: center;
      justify-items: center;
      margin: 20px 0;
    }
    
    .matrix-header {
      font-weight: bold;
      text-align: center;
    }

    .matrix-corner {
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: bold;
      background: #f8f8f8;
      border-bottom: 2px solid #ccc;
      border-right: 2px solid #ccc;
      padding-right: 5px;
      font-size: 0.78em;
      text-align: right;
    }

    .column-header {
      text-align: center;
      padding-bottom: 5px;
      font-size: 1rem; /* adjust as needed */
    }



  </style>
</head>
<body>
  <h2 style="text-align: center;">Demo page of paper : ‚Äú Bujard Balthazar, Nika J√©r√¥me, Obin Nicolas, Bevilacqua Fr√©d√©ric,
     Learning Relationships between Separate Audio Tracks for Creative Applications, Proceedings of the 6th Conference on 
     AI Music Creativity (AIMC 2025), 2025"</h2>
  <!-- üîπ Summary Section -->
<div class="summary-section">
  <p>
    This web page presents the main results from the 2025 AIMC paper "Learning Relationships between Separate Audio Tracks 
    for Creative Applications" (Bujard et al., 2025), along with some audio examples. The related code can be found 
    <a href="https://github.com/ircam-ismm/learning-from-paired-tracks">here</a>.
  </p>
</div>

<!-- üîπ Figures Section -->
<div class="figures-section">
  <h3>Model summary</h3>
  <div class="figure">
    <img src="figures/schema page demo/schema page demo.001.jpeg" alt="Figure 1" />
    <p class="caption">Figure 1 ‚Äì Model summary : audio input (guide) is encoded by the Perception module, the Decision learns symbolic relationships from a 
      dataset of paired tracks and predicts a symbolic specification given the encoded input, the Action module uses the symbolic specification and a 
      'memory' audio file to generate the musical response with corpus-based concatenative synthesis.
      
    </p>
  </div>
</div>

<div class="summary-section">
  <p>
    The audio examples below are composed of : 'guide', 'memory' and output audios corresponding to, respectively, the input of the model,
    the memory used by Dicy2 and the mix 'guide' + model output. The 'Selected examples' are well selected audios that present good musical properties (harmonicity, tonality, variations).
    Then, the "Examples illustrating future work directions" present all 9 configurations (window_size X alphabet size) for some examples that enable some discussion
    regarding the main results and future works of the paper. Each example is completed with a comment summarizing the results of highlighted examples.
  </p>
  <p>
    Readers and listeners are invited to read the corresponding paper before delving into the following examples, specifically Sections 6 (Results) and 7 (Discussion).
  <p\>
  <p>
    The main results and conclusions are summarized in the following :
  </p>
  <p>
    - The primary factor influencing the model's performance was found to be the alphabet size
  </p>
  <p>
    - Increased alphabet size is associated with enhanced diversity...
  </p>
  <p>
    - But,  modeling the relationships between tracks becomes more arduous.
  </p>
  <p>
    - The window size did not exhibit clear patterns, but MoisesDB (containing western pop music, i.e. pulsed music) favoured window sizes close to its pulsation (bpm).
  </p>
  
</div>

<div id="audioContent"></div>

<script>
const root = 'moises';

const allConfigs = [
  "0.25s_A16", "0.35s_A16", "0.5s_A16",
  "0.25s_A64", "0.35s_A64", "0.5s_A64",
  "0.25s_A256", "0.35s_A256", "0.5s_A256"
];

const examplesNice = [
  {
    name: "0e0d",
    basePath: "0e0d",
    topFiles: ['guide.mp3','memory.mp3'],
    path : `moises/0e0d/0.5s_A16.mp3`,
    cfg : "window size : 500ms, alphabet size : 16",
    instruments : ["piano","guitar"],
  },
  {
    name: "747d",
    basePath: "747d",
    topFiles: ['guide.mp3','memory.mp3'],
    path : `moises/747d/0.5s_A16.mp3`,
    cfg : "window size : 500ms, alphabet size : 16",
    instruments : ["vocals","guitar"],
  },
  {
    name: "f010",
    basePath: "f010",
    topFiles: ['guide.mp3','memory.mp3'],
    path : `moises/f010/0.5s_A64.mp3`,
    cfg : "window size : 500ms, alphabet size : 64",
    instruments : ["synth","guitar"],
  },
];

const exampleSets = [
  // {
  //   name: "6c70",
  //   basePath: "6c70",
  //   topFiles: ['guide.mp3','memory.mp3'],
  //   examples: [
  //     { path:`moises/${name}/0.5s_A16.mp3`, accuracy: 18, max_len: 4, entropy:2.1},
  //     { path:`moises/${name}/0.5s_A256.mp3`, accuracy:10, max_len:4, entropy:1.8},
  //     { path:`moises/${name}/0.5s_A64.mp3`, accuracy:17, max_len:12, entropy:2}
  //   ],
  //   comment : "Harmonic relationship and mode change example. The input source is the piano and the guitar is the memory. \
  //   Further work on the size of the alphabet is crucial, rather than using arbitrary alphabets. It's clear from this example \
  //   that an arbitrary alphabet that's too small leads to a lot of repetition, and an arbitrary alphabet that's too large leads to either no \
  //   solution or a lot of silence. A silent segment can be volountarly selected by the model or no \
  //   match in the memory was found for that symbolic specification. In this example A64 = (mostly) no match and A256 = (mostly) volountary silence."
  //   // comment: "Harmonic relationship and mode change example. The input source is the piano and the guitar is the memory. \
  //   // First of all, the 0.5s A16 example is not synchronized with the input source. This indicates that even a uniform segmentation window \
  //   // does not guarantee synchronization between the response and the source. On the 500ms column, we observe that as the size of the alphabet \
  //   // increases, the response becomes more silent. This is due to two scenarios : a silent segment is volountarly selected by the model or no \
  //   // match in the memory was found for that symbolic specification. In this example A64 = no match and A256 = volountary silence."
  // },
  {
    name: "0358",
    basePath: "0358",
    topFiles: ['guide.mp3','memory.mp3'],
    examples: [
      { path:`moises/${name}/0.5s_A16.mp3`, accuracy: 33, max_len: 9, entropy:1.9 },
      // { path:`moises/${name}/0.35s_A256.mp3`, accuracy:9, max_len:2, entropy:3.5 },
      // { path:`moises/${name}/0.5s_A64.mp3`, accuracy:10.5, max_len:3, entropy:2.7 }
    ],
    // comment : "Intensity follow-up example. The piano is the input source and the guitar serves as memory. There is no general comment on the\
    // comparison between configurations. But, it can be noted that the 500ms window and alpabet size = 16 configuration reproduces the intensity follow-up interaction. \
    // response starts calmly and when the piano gains in intensity the response follows this evolution. The response aloso presents well suited harmonic relaionship with \
    // the input source. This shows that this configuration, not only learned harmonic relatioonships but also how to follow intensity variations. \
    // This observation prompts us to investigate what is encoded in the tokens coming from the Perception module."
    comment: "Intensity follow-up example. The piano is the input source and the guitar serves as memory. In this example, the \
    melodic-harmonic relationship between guide and output is not very satisfactory, but we observe \
    that a jump in intensity in the guide implies a jump in intensity in the output, which invites us, firstly, to investigate more \
    deeply what is encoded by our perception module, and, secondly, to study our decision module with symbols that represent values \
    known to decorrelate the two works."
  },
  {
    name: "04f2",
    basePath: "04f2",
    topFiles: ['guide.mp3','memory.mp3'],
    examples: [
      { path:`moises/${name}/0.5s_A16.mp3`, accuracy: 9, max_len: 7, entropy:0.88},
      { path:`moises/${name}/0.5s_A256.mp3`, accuracy:21, max_len:6, entropy:1.7},
      { path:`moises/${name}/0.5s_A64.mp3`, accuracy:5, max_len:6, entropy:1.6}
    ],
    comment:"Lead - Accompaniment relationship example. The piano is the input source and corresponds to the Lead instrument, the bass is the accompaniment \
    instrument serving as memory. We note that the 500ms and 16 alphabet size configuration does not work; the chosen segemnt is not in the correct tonality. But, \
    when incresing the alphabet size the response is more coherent (harmonicity between source and response). This hints that a small vocabulary \
    does not allow the model to select segments in the correct tonality, maybe because the class distribution is too coarse. While larger alphabets enable the \
    selection of segemnts in the correct tonality."
  },
];

const container = document.getElementById("audioContent");

// Section title
const title = document.createElement("div");
title.className = "category-title";
title.textContent = "Selected examples";
container.appendChild(title);

// // Section text
// const text = document.createElement("div");
// text.className = "summary-section";
// text.textContent = "Below are presented 3 'good' examples";
// container.appendChild(text);

// Header row
const headerRow = document.createElement("div");
headerRow.className = "memory-guide-row";

// Empty cells for Memory & Guide
examplesNice[0].topFiles.forEach(file => {
  const empty = document.createElement("div");
  empty.className = "audio-container";
  empty.textContent = file.replace(".mp3","")
  headerRow.appendChild(empty);
});

// Output + Guide header cell
const outputHeader = document.createElement("div");
outputHeader.className = "audio-container";

const headerText = document.createElement("div");
headerText.className = "column-header";
headerText.textContent = "Output + Guide";

outputHeader.appendChild(headerText);
headerRow.appendChild(outputHeader);

// Append header row before examples
container.appendChild(headerRow);


examplesNice.forEach(example => {
  // Example title
  // const exampleTitle = document.createElement("h3");
  // exampleTitle.className = "category-title";
  // exampleTitle.textContent = `Example: ${example.name}`;
  // container.appendChild(exampleTitle);

  // Row containing Memory, Guide, Output
  const exampleRow = document.createElement("div");
  exampleRow.className = "memory-guide-row"; // flex container for all three

  // Memory & Guide
  example.topFiles.forEach((file,idx) => {
    const fileContainer = document.createElement("div");
    fileContainer.className = "audio-container";

    const label = document.createElement("p");
    label.textContent = `${example.instruments[idx]}`;

    const audio = document.createElement("audio");
    audio.controls = true;
    audio.preload = "none";
    audio.src = `moises/${example.basePath}/${file}`;

    fileContainer.appendChild(label);
    fileContainer.appendChild(audio);
    exampleRow.appendChild(fileContainer);
  });

  // Output
  const outputContainer = document.createElement("div");
  outputContainer.className = "audio-container";

  const outputLabel = document.createElement("p");
  outputLabel.textContent = example.cfg;

  const outputAudio = document.createElement("audio");
  outputAudio.controls = true;
  outputAudio.preload = "none";
  outputAudio.src = example.path;

  outputContainer.appendChild(outputLabel);
  outputContainer.appendChild(outputAudio);
  exampleRow.appendChild(outputContainer);

  // Append row
  container.appendChild(exampleRow);

});

// Separator
const separator = document.createElement("hr");
separator.className = "separator";
container.appendChild(separator);

// New section title
const newSectionTitle = document.createElement("div");
newSectionTitle.className = "category-title";
newSectionTitle.textContent = "Examples illustrating future work directions";
container.appendChild(newSectionTitle);

exampleSets.forEach(set => {
  const section = document.createElement('div');
  section.className = 'category-section';

  // // Example title
  // const title = document.createElement('div');
  // title.className = 'category-title';
  // title.textContent = `Example: ${set.name}`;
  // section.appendChild(title);

  // Comment box
  if (set.comment) {
    const commentBox = document.createElement('div');
    commentBox.className = 'summary-section';
    commentBox.textContent = set.comment;
    section.appendChild(commentBox);
  }

  // Top files (Memory + Guide row)
  const topRow = document.createElement('div');
  topRow.className = 'memory-guide-row';
  set.topFiles.forEach(file => {
    const fileContainer = document.createElement('div');
    fileContainer.className = 'audio-container large-audio';

    const label = document.createElement('p');
    label.textContent = file.replace('.mp3', '').replace('_',' ');

    const audio = document.createElement('audio');
    audio.controls = true;
    audio.src = `${root}/${set.basePath}/${file}`;
    audio.preload = "none";

    fileContainer.appendChild(label);
    fileContainer.appendChild(audio);
    topRow.appendChild(fileContainer);
  });
  section.appendChild(topRow);

  //Top header for output+guide title
  // Output + Guide header cell
  const outputHeader = document.createElement("div");
  outputHeader.className = "audio-container";

  const headerText = document.createElement("div");
  headerText.className = "column-header";
  headerText.textContent = "Output + Guide Matrix";
  section.appendChild(headerText);

  // Grid with headers
  const matrixContainer = document.createElement('div');
  matrixContainer.className = 'matrix-grid';

  // First row (top-left corner label + column headers)
  const cornerDiv = document.createElement('div');
  cornerDiv.className = 'matrix-corner';
  cornerDiv.textContent = 'Window Size ‚Üí  Alphabet Size ‚Üì';
  matrixContainer.appendChild(cornerDiv);

  // Column headers
  ['250ms', '350ms', '500ms'].forEach(header => {
    const headerDiv = document.createElement('div');
    headerDiv.className = 'matrix-header';
    headerDiv.textContent = header;
    matrixContainer.appendChild(headerDiv);
  });

  // Rows
  ['16', '64', '256'].forEach((rowLabel, rowIndex) => {
    // Row header
    const rowHeaderDiv = document.createElement('div');
    rowHeaderDiv.className = 'matrix-header';
    rowHeaderDiv.textContent = rowLabel;
    matrixContainer.appendChild(rowHeaderDiv);

    // Audio cells for this row
    ['250ms', '350ms', '500ms'].forEach((colLabel, colIndex) => {
      const cfgIndex = rowIndex * 3 + colIndex;
      const cfg = allConfigs[cfgIndex];

      const audioBox = document.createElement('div');
      audioBox.className = 'audio-container large-audio';

      const label = document.createElement('p');
      label.textContent = cfg.replace("_"," ");

      const audio = document.createElement('audio');
      audio.controls = true;
      audio.src = `${root}/${set.basePath}/${cfg}.mp3`;
      audio.preload = "none";

      // Metrics if present
      const metrics = document.createElement('div');
      metrics.className = 'metrics';
      const highlightExample = set.examples.find(e => e.path.includes(cfg));
      if (highlightExample) {
        metrics.innerHTML = `
          <small><b>Accuracy:</b> ${(highlightExample.accuracy).toFixed(1)}%</small><br>
          <small><b>Max Len:</b> ${highlightExample.max_len}</small><br>
          <small><b>Entropy:</b> ${highlightExample.entropy.toFixed(2)} [Bits]</small>
        `;
        audioBox.style.fontWeight = 'bold';
        audioBox.style.color = '#000';
      } else {
        audioBox.style.opacity = '0.7';
      }

      audioBox.appendChild(label);
      audioBox.appendChild(audio);
      audioBox.appendChild(metrics);
      matrixContainer.appendChild(audioBox);
    });
  });

  section.appendChild(matrixContainer);
  section.appendChild(document.createElement('hr'));
  container.appendChild(section);
});



</script>
</body>
</html>
